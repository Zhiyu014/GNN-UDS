astlingen:
  env: astlingen
  directed: False
  length: 0
  order: 1
  graph_base: 0
  control_interval: 5
  setting_duration: 5
  act: 'False'
  mac: False
  dec: False

  # Arguments for RL process
  train: False
  episodes: 5000
  batch_size: 128 # batch size of the training data
  limit: 22 # maximum capacity of the replay buffer
  tune_gap: 0 # finetune the model per tune_gap
  sample_gap: 0 # sample data with swmm per sample gap
  start_gap: 100 # start updating agent after start gap
  eval_gap: 10 # evaluate the agent per eval_gap
  save_gap: 1000 # save the agent & state_norm per save_gap

  # Arguments for the model rollout
  data_dir: ./envs/data/astlingen/
  model_based: False # if use model-based sampling
  horizon: 60 # horizon length
  model_dir: ./model/astlingen/
  epsilon: -1.0
  epochs: 100 # model update times per episode

  # Arguments for the agent
  agent: SAC  # agent name
  conv: GATconv
  use_pred: False  # if use prediction runoff as states
  net_dim: 128 # dimension of hidden layers
  n_layer: 3 # number of network layers
  conv_dim: 128 # dimension of hidden layers
  n_sp_layer: 3 # number of network layers
  activation: relu # if use dueling layer
  agent_dir: ./agent/astlingen/ # the working directory
  load_agent: False # if load the current model

  # Arguments for the agent update
  repeats: 5
  norm: False # normalize the reward
  scale: 1.0 # scale the reward
  gamma: 0.98 # discouted rate
  en_disc: 0.5 # target entropy discouted factor
  act_lr: 0.0001 # learning rate for actor
  cri_lr: 0.001 # learning rate for critic
  update_interval: 0.005 # update the target network per update_interval
  epsilon_decay: 0.9996 # epsilon decay rate for deterministic q learning
  noise_std: 0.05 # std of the exploration noise
  value_tau: 0.0 # value running average tau

  # Arguments for the testing
  test: False
  rain_dir: ./envs/config/  # rainfall info dir
  rain_suffix:  # rain_suffix
  rain_num: 50 # exploration events
  swmm_step: 1
  processes: 1
  result_dir: ./results/astlingen/ # the result directory

chaohu:
  env: chaohu
  directed: False
  length: 0
  order: 1
  graph_base: 0
  control_interval: 10
  setting_duration: 10
  act: 'False'
  mac: False
  dec: False

  # Arguments for RL process
  train: False
  episodes: 5000
  batch_size: 64 # batch size of the training data
  limit: 22 # maximum capacity of the replay buffer
  tune_gap: 0 # finetune the model per tune_gap
  sample_gap: 0 # sample data with swmm per sample gap
  start_gap: 100 # start updating agent after start gap
  eval_gap: 10 # evaluate the agent per eval_gap
  save_gap: 1000 # save the agent & state_norm per save_gap

  # Arguments for the model rollout
  data_dir: ./envs/data/chaohu/
  model_based: False # if use model-based sampling
  horizon: 60 # horizon length
  model_dir: ./model/chaohu/
  epsilon: -1.0
  epochs: 100 # model update times per episode

  # Arguments for the agent
  agent: SAC  # agent name
  conv: GATconv
  use_pred: False  # if use prediction runoff as states
  net_dim: 128 # dimension of hidden layers
  n_layer: 3 # number of network layers
  conv_dim: 128 # dimension of hidden layers
  n_sp_layer: 3 # number of network layers
  activation: relu # if use dueling layer
  agent_dir: ./agent/chaohu/ # the working directory
  load_agent: False # if load the current model

  # Arguments for the agent update
  repeats: 5
  norm: False # normalize the reward
  scale: 1.0 # scale the reward
  gamma: 0.95 # discouted rate
  en_disc: 0.5 # target entropy discouted factor
  act_lr: 0.0001 # learning rate for actor
  cri_lr: 0.001 # learning rate for critic
  update_interval: 0.005 # update the target network per update_interval
  epsilon_decay: 0.9996 # epsilon decay rate for deterministic q learning
  noise_std: 0.05 # std of the exploration noise
  value_tau: 0.0 # value running average tau

  # Arguments for the testing
  test: False
  rain_dir: ./envs/config/  # rainfall info dir
  rain_suffix:  # rain_suffix
  rain_num: 50 # exploration events
  swmm_step: 1
  processes: 1
  result_dir: ./results/chaohu/ # the result directory
